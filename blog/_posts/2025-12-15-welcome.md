---
layout: post
title: "The Worlds Project"
---

# Intro

This project began life as a question ...

*Can "emergent behaviors" be witnessed in something a desktop PC can do, or is that an "at scale"  phenomenon?*

I started with "I want to see critters do unexpected things" and began the process of scaling that concept down to a plan I thought I could pull off, seeing as how this is a spare time project.

This project is also a chance to get more experience with utilizing AI and finding out what works for me. 

That said, there's no AI-generated code in this project. As a best practice for my workflow, I purposefully try to avoid telling models anything specific about my development tools or language, so that I can get what helps me the most: high-level concepts explained logically from a general coding perspective, so I understand the problem space better. I can turn that understanding into the code myself, but especially in this project, I needed much better understanding of what I was even trying to do.

The first phase was mostly with ChatGPT, discussing what's needed to be able to witness something like emergent behaviors. Is it even possible for one dude to write something that would have any kind of interesting result? The assurances I got from those first conversations boiled down to this:

- it's not about scale
- it's not about population size

After spending some time doing proof of concept coding, I circled back to focus on the design. At this point, I switched to Copilot in VS Code, with a manual selection of GPT-5.2. VS Code allows me to at least try to be more organized, since copilot can read documents where I have my questions/prompts, and it can update design documents itself as we discuss things.

This workflow allowed me to plow through a lot of design discussions, generate a lot of notes, and have an informed perspective - *to a degree* - of the big players within the project.

## Thus, we begin.

I consider this the real starting point for this project, and it's not normal. After reaching a point in the design of both where stuff is happening, and how stuff happens, it became clear that without some form of visualization early on, I was going to be banging my head on the desk a lot. The *type* of coding I needed to do was a little unfamiliar and it needs to be done "right" *consistently* to produce the kind of results I want. 

So, first ... the UI and Geography.



